<!doctype html>
<html>

<head>
  <title>Speech Recognition Demo</title>
  <meta charset="utf-8" />
  <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    *,
    *::before,
    *::after {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100vh;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
      text-align: center;
      background: #000;
      color: #fff;
      overflow: hidden;
    }

    main {
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      width: 80%;
      margin-top: 10vh;
    }

    button {
      padding: 0.5em 1.5em;
      margin-top: 20px;
      color: #fff;
      background: #007bff;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-size: 1.15em;
      font-weight: bold;
      transition: background-color 0.3s, transform 0.3s;
    }

    button:hover {
      background-color: #0056b3;
      transform: translateY(-2px);
    }

    #visualizer {
      height: 200px;
      width: 100%;
      display: flex;
      align-items: flex-end;
      justify-content: center;
      overflow: hidden;
      margin: 0 auto;
    }

    #visualizer > div {
      width: 5px;
      min-height: 2px; /* Ensure there's always a visible bar */
      background-color: #fff;
      margin: 2px;
      transition: height 0.3s ease, background-color 0.3s ease;
    }

    #finalTranscript {
      padding: 20px;
      margin-top: 20px;
      background: rgba(255, 255, 255, 0.1);
      border-radius: 8px;
      color: #fff;
      font-size: 1.2em;
      width: 80%;
      max-width: 700px;
      overflow-y: auto;
      max-height: 150px;
      text-align: left;
      word-wrap: break-word;
    }
  </style>
</head>

<body>
  <main>
    <div id="visualizer"></div>
    <button onclick="toggleRecognition()">Start</button>
    <div id="finalTranscript">Final Transcript will appear here...</div>
  </main>
  <script>
    let audioContext;
    let analyser;
    let dataArray;
    let streamSource;
    let recognition;
    let isListening = false;
    const visualMainElement = document.getElementById('visualizer');
    const transcriptDiv = document.getElementById('finalTranscript');
    const toggleButton = document.querySelector('button');

    // Initialize visualizer bars
    function createVisualizerBars(count) {
        visualMainElement.innerHTML = '';
        for (let i = 0; i < count; i++) {
            const bar = document.createElement('div');
            visualMainElement.appendChild(bar);
        }
    }

    // Update visualizer bars according to frequency data
    function updateVisualizer(frequencyData) {
        const bars = visualMainElement.children;
        for (let i = 0; i < bars.length; i++) {
            const bar = bars[i];
            const barHeight = (frequencyData[i] / 255) * 200; // Scale the frequency value to the visualizer height
            bar.style.height = `${barHeight}px`;
        }
    }

    // Toggle recognition on and off
    function toggleRecognition() {
        if (isListening) {
            stopRecognition();
        } else {
            startRecognition();
        }
    }

    // Start speech recognition and audio processing
    function startRecognition() {
        if (!audioContext) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;
            dataArray = new Uint8Array(analyser.frequencyBinCount);
        }

        navigator.mediaDevices.getUserMedia({ audio: true, video: false })
            .then((stream) => {
                streamSource = audioContext.createMediaStreamSource(stream);
                streamSource.connect(analyser);
                animateVisualizer(); // Start visualizing audio
            })
            .catch(error => {
                console.error('Error accessing the microphone', error);
                transcriptDiv.textContent = 'Error accessing the microphone: ' + error;
            });

        if (!recognition) {
            recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.lang = 'en-US';
            recognition.continuous = true;
            recognition.interimResults = true; // Allow interim results for real-time feedback

            recognition.onstart = () => {
                isListening = true;
                toggleButton.textContent = 'Stop';
                transcriptDiv.textContent = ''; // Clear previous text
            };

            recognition.onresult = (event) => {
                let transcript = '';
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    transcript += event.results[i][0].transcript;
                }
                transcriptDiv.textContent = transcript; // Update the displayed text
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error', event);
                transcriptDiv.textContent = 'Recognition error: ' + event.error;
            };

            recognition.onend = () => {
                isListening = false;
                toggleButton.textContent = 'Start';
            };
        }

        recognition.start();
    }

    function addTranscript(transcript) {
    const existingContent = outputDiv.innerHTML.trim();
    const words = transcript.split(' ');
    if (words.length >= 5) { // Check if there are at least 5 words
        const lines = [];
        for (let i = 0; i < words.length; i += 5) {
            lines.push(words.slice(i, i + 5).join(' '));
        }
        setTimeout(() => {
            outputDiv.innerHTML += lines.join('<br>') + '<br><br>';
            if (outputDiv.querySelectorAll('br').length >= 6) { // Check if already 3 lines
                clearTranscript();
            }
        }, 5000); // Delay of 5 seconds (5000 milliseconds) before appending
    }
}

    // Animate visualizer based on audio data
    function animateVisualizer() {
        if (!audioContext) {
            return;
        }
        analyser.getByteFrequencyData(dataArray);
        updateVisualizer(dataArray);
        requestAnimationFrame(animateVisualizer);
    }

    createVisualizerBars(64);
    
</script>

</body>
</html>
